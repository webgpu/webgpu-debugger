<!DOCTYPE html>
<html>
<head>
    <title>Basic Spinning Cube</title>
    <script src="../capture/registry.js"></script>
    <script src="../replay/lib.js"></script>
    <style>
    html, body { margin: 0; height: 100% }

    #fail {
        position: fixed;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
        background: red;
        color: white;
        font-weight: bold;
        font-family: monospace;
        font-size: 16pt;
        text-align: center;
    }
    </style>
</head>
<body>
<canvas id="renderCanvas" width=400 height=400></canvas>
<canvas id="captureCanvas" width=1 height=1></canvas>
<div id="fail" style="display: none">
    <div class="content"></div>
</div>
<script type="module">

/* global GPUBufferUsage */
/* global GPUTextureUsage */

import {vec3, mat4} from 'https://webgpufundamentals.org/webgpu/resources/js/wgpu-matrix.module.js';

async function main() {
    const gpu = navigator.gpu;
    if (!gpu) {
        fail('this browser does not support webgpu');
        return;
    }

    const adapter = await gpu.requestAdapter();
    if (!adapter) {
        fail('this browser appears to support WebGPU but it\'s disabled');
        return;
    }

    const device = await adapter.requestDevice();

    const canvas = document.querySelector('#renderCanvas');
    const context = canvas.getContext('webgpu');

    const presentationFormat = gpu.getPreferredCanvasFormat(adapter);
    context.configure({
        device,
        format: presentationFormat,
    });

    const canvasInfo = {
        canvas,
        context,
        presentationFormat,
        // these are filled out in resizeToDisplaySize
        renderTarget: undefined,
        renderTargetView: undefined,
        depthTexture: undefined,
        depthTextureView: undefined,
        sampleCount: 4,    // can be 1 or 4
    };

    const shaderSrc = `
    struct VSUniforms {
        worldViewProjection: mat4x4<f32>,
        worldInverseTranspose: mat4x4<f32>,
    };
    @group(0) @binding(0) var<uniform> vsUniforms: VSUniforms;

    struct MyVSInput {
            @location(0) position: vec4<f32>,
            @location(1) normal: vec3<f32>,
            @location(2) texcoord: vec2<f32>,
    };

    struct MyVSOutput {
        @builtin(position) position: vec4<f32>,
        @location(0) normal: vec3<f32>,
        @location(1) texcoord: vec2<f32>,
    };

    @vertex
    fn myVSMain(v: MyVSInput) -> MyVSOutput {
        var vsOut: MyVSOutput;
        vsOut.position = vsUniforms.worldViewProjection * v.position;
        vsOut.normal = (vsUniforms.worldInverseTranspose * vec4<f32>(v.normal, 0.0)).xyz;
        vsOut.texcoord = v.texcoord;
        return vsOut;
    }

    struct FSUniforms {
        lightDirection: vec3<f32>,
    };

    @group(0) @binding(1) var<uniform> fsUniforms: FSUniforms;
    @group(0) @binding(2) var diffuseSampler: sampler;
    @group(0) @binding(3) var diffuseTexture: texture_2d<f32>;

    @fragment
    fn myFSMain(v: MyVSOutput) -> @location(0) vec4<f32> {
        var diffuseColor = textureSample(diffuseTexture, diffuseSampler, v.texcoord);
        var a_normal = normalize(v.normal);
        var l = dot(a_normal, fsUniforms.lightDirection) * 0.5 + 0.5;
        return vec4<f32>(diffuseColor.rgb * l, diffuseColor.a);
    }
    `;

    function createBuffer(device, data, usage) {
        const buffer = device.createBuffer({
            size: data.byteLength,
            usage,
            mappedAtCreation: true,
        });
        const dst = new data.constructor(buffer.getMappedRange());
        dst.set(data);
        buffer.unmap();
        return buffer;
    }

    const positions = new Float32Array([1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1]);
    const normals   = new Float32Array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1]);
    const texcoords = new Float32Array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]);
    const indices   = new Uint16Array([0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23]);

    const positionBuffer = createBuffer(device, positions, GPUBufferUsage.VERTEX);
    const normalBuffer   = createBuffer(device, normals, GPUBufferUsage.VERTEX);
    const texcoordBuffer = createBuffer(device, texcoords, GPUBufferUsage.VERTEX);
    const indicesBuffer  = createBuffer(device, indices, GPUBufferUsage.INDEX);

    const tex = device.createTexture({
        size: [2, 2, 1],
        format: 'rgba8unorm',
        usage:
            GPUTextureUsage.TEXTURE_BINDING |
            GPUTextureUsage.COPY_DST,
    });
    device.queue.writeTexture(
        { texture: tex },
        new Uint8Array([
            255, 255, 128, 255,
            64, 128, 128, 128,
            255, 128, 255, 255,
            255, 128, 128, 255,
        ]),
        { bytesPerRow: 8, rowsPerImage: 2 },
        { width: 2, height: 2 },
    );

    const sampler = device.createSampler({
        magFilter: 'nearest',
        minFilter: 'nearest',
    });

    async function createShaderModule(device, code) {
        //device.pushErrorScope('validation');
        const shader = device.createShaderModule({code});
        //const error = await device.popErrorScope();
        //if (error) {
        //    throw new Error(error.message);
        //}
        return shader;
    }

    const shaderModule = await createShaderModule(device, shaderSrc);

    //device.pushErrorScope('validation');
    const pipeline = device.createRenderPipeline({
        layout: 'auto',
        vertex: {
            module: shaderModule,
            entryPoint: 'myVSMain',
            buffers: [
                // position
                {
                    arrayStride: 3 * 4, // 3 floats, 4 bytes each
                    attributes: [
                        {shaderLocation: 0, offset: 0, format: 'float32x3'},
                    ],
                },
                // normals
                {
                    arrayStride: 3 * 4, // 3 floats, 4 bytes each
                    attributes: [
                        {shaderLocation: 1, offset: 0, format: 'float32x3'},
                    ],
                },
                // texcoords
                {
                    arrayStride: 2 * 4, // 2 floats, 4 bytes each
                    attributes: [
                        {shaderLocation: 2, offset: 0, format: 'float32x2',},
                    ],
                },
            ],
        },
        fragment: {
            module: shaderModule,
            entryPoint: 'myFSMain',
            targets: [
                {
                    format: presentationFormat,
                    blend: {
                        color: {
                            srcFactor: 'one',
                            dstFactor: 'one-minus-src-alpha',
                            operation: 'add',
                        },
                        alpha: {
                            srcFactor: 'one',
                            dstFactor: 'one-minus-src-alpha',
                            operation: 'add',
                        },
                    },
                },
            ],
        },
        primitive: {
            topology: 'triangle-list',
            cullMode: 'none',
        },
        depthStencil: {
            depthWriteEnabled: true,
            depthCompare: 'less',
            format: 'depth24plus',
        },
        ...(canvasInfo.sampleCount > 1 && {
                multisample: {
                    count: canvasInfo.sampleCount,
                },
        }),
    });
    //const error = await device.popErrorScope();
    //if (error) {
    //    throw new Error('failed to create pipeline');
    //}

    const vUniformBufferSize = 2 * 16 * 4; // 2 mat4s * 16 floats per mat * 4 bytes per float
    const fUniformBufferSize = 3 * 4;            // 1 vec3 * 3 floats per vec3 * 4 bytes per float

    const vsUniformBuffer = device.createBuffer({
        size: vUniformBufferSize,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });
    const fsUniformBuffer = device.createBuffer({
        size: fUniformBufferSize,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });
    const vsUniformValues = new Float32Array(2 * 16); // 2 mat4s
    const worldViewProjection = vsUniformValues.subarray(0, 16);
    const worldInverseTranspose = vsUniformValues.subarray(16, 32);
    const fsUniformValues = new Float32Array(3);    // 1 vec3
    const lightDirection = fsUniformValues.subarray(0, 3);

    const bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
            { binding: 0, resource: { buffer: vsUniformBuffer } },
            { binding: 1, resource: { buffer: fsUniformBuffer } },
            { binding: 2, resource: sampler },
            { binding: 3, resource: tex.createView() },
        ],
    });

    const renderPassDescriptor = {
        colorAttachments: [
            {
                // view: undefined, // Assigned later
                // resolveTarget: undefined, // Assigned Later
                clearValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },
                loadOp: 'clear',
                storeOp: 'store',
                
            },
        ],
        depthStencilAttachment: {
            // view: undefined,    // Assigned later
            depthClearValue: 1,
            depthLoadOp: 'clear',
            depthStoreOp: 'store',
        },
    };

    function resizeToDisplaySize(device, canvasInfo) {
        const {
            canvas,
            renderTarget,
            presentationFormat,
            depthTexture,
            sampleCount,
        } = canvasInfo;
        const width = Math.min(device.limits.maxTextureDimension2D, canvas.clientWidth);
        const height = Math.min(device.limits.maxTextureDimension2D, canvas.clientHeight);

        const needResize = !canvasInfo.renderTarget ||
                                             width !== canvas.width ||
                                             height !== canvas.height;
        if (needResize) {
            if (renderTarget) {
                renderTarget.destroy();
            }
            if (depthTexture) {
                depthTexture.destroy();
            }

            canvas.width = width;
            canvas.height = height;

            if (sampleCount > 1) {
                const newRenderTarget = device.createTexture({
                    size: [canvas.width, canvas.height],
                    format: presentationFormat,
                    sampleCount,
                    usage: GPUTextureUsage.RENDER_ATTACHMENT,
                });
                canvasInfo.renderTarget = newRenderTarget;
                canvasInfo.renderTargetView = newRenderTarget.createView();
            }

            const newDepthTexture = device.createTexture({
                size: [canvas.width, canvas.height],
                format: 'depth24plus',
                sampleCount,
                usage: GPUTextureUsage.RENDER_ATTACHMENT,
            });
            canvasInfo.depthTexture = newDepthTexture;
            canvasInfo.depthTextureView = newDepthTexture.createView();
        }
        return needResize;
    }

    function render(time) {
        time *= 0.001;
        resizeToDisplaySize(device, canvasInfo);

        const projection = mat4.perspective(30 * Math.PI / 180, canvas.clientWidth / canvas.clientHeight, 0.5, 10);
        const eye = [1, 4, -6];
        const target = [0, 0, 0];
        const up = [0, 1, 0];

        const camera = mat4.lookAt(eye, target, up);
        const view = mat4.inverse(camera);
        const viewProjection = mat4.multiply(projection, view);
        const world = mat4.rotationY(time);
        mat4.transpose(mat4.inverse(world), worldInverseTranspose);
        mat4.multiply(viewProjection, world, worldViewProjection);

        vec3.normalize([1, 8, -10], lightDirection);

        device.queue.writeBuffer(
            vsUniformBuffer,
            0,
            vsUniformValues.buffer,
            vsUniformValues.byteOffset,
            vsUniformValues.byteLength,
        );
        device.queue.writeBuffer(
            fsUniformBuffer,
            0,
            fsUniformValues.buffer,
            fsUniformValues.byteOffset,
            fsUniformValues.byteLength,
        );

        if (canvasInfo.sampleCount === 1) {
                const colorTexture = context.getCurrentTexture();
                renderPassDescriptor.colorAttachments[0].view = colorTexture.createView();
        } else {
            renderPassDescriptor.colorAttachments[0].view = canvasInfo.renderTargetView;
            renderPassDescriptor.colorAttachments[0].resolveTarget = context.getCurrentTexture().createView();
        }
        renderPassDescriptor.depthStencilAttachment.view = canvasInfo.depthTextureView;

        const commandEncoder = device.createCommandEncoder();
        const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
        passEncoder.setPipeline(pipeline);
        passEncoder.setBindGroup(0, bindGroup);
        passEncoder.setVertexBuffer(0, positionBuffer);
        passEncoder.setVertexBuffer(1, normalBuffer);
        passEncoder.setVertexBuffer(2, texcoordBuffer);
        passEncoder.setIndexBuffer(indicesBuffer, 'uint16');
        passEncoder.drawIndexed(indices.length);
        passEncoder.end();
        device.queue.submit([commandEncoder.finish()]);

        requestAnimationFrame(render);
    }

    spector2.traceFrame().then(async (trace) => {
        // Trace the frame and set up the replay.
        console.log(trace);
        spector2.revertEntryPoints();
        const replay = await loadReplay(trace);
        console.log(replay);

        // Go through each command, and show the presented texture of the trace on the capture canvas.
        const captureCanvas = document.getElementById('captureCanvas');
        const context = captureCanvas.getContext('webgpu');

        for (const c of replay.commands) {
            replay.execute(c);

            if (c.name === 'present') {
                const textureState = c.args.texture;
                const device = textureState.device.webgpuObject;

                captureCanvas.width = textureState.size.width;
                captureCanvas.height = textureState.size.height;
                context.configure({
                    device,
                    usage: GPUTextureUsage.COPY_DST,
                    format: textureState.format,
                    alphaMode: 'opaque',
                });

                const encoder = device.createCommandEncoder();
                encoder.copyTextureToTexture(
                    {texture: textureState.webgpuObject},
                    {texture: context.getCurrentTexture()},
                    textureState.size
                );
                device.queue.submit([encoder.finish()]);
            }
        }
    });

    requestAnimationFrame(render);
}

function fail(msg) {
    const elem = document.querySelector('#fail');
    const contentElem = elem.querySelector('.content');
    elem.style.display = '';
    contentElem.textContent = msg;
}

main();
    
</script>
</body>
</html>
