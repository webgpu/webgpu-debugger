<!DOCTYPE html>
<html>
<head>
    <title>Basic Animated Triangle for development.</title>
</head>
<body>
<canvas id="renderCanvas" width=400 height=400></canvas>
<canvas id="captureCanvas" width=1 height=1></canvas>
<script type="module">
import {spector2} from "/dist/capture.js";
import {loadReplay} from "/dist/replay.js";
async function run() {
    const adapter = await navigator.gpu.requestAdapter();
    const device = await adapter.requestDevice();

    const context = document.getElementById("renderCanvas").getContext('webgpu');
    const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
    context.configure({
        device,
        format: presentationFormat,
        alphaMode: 'opaque',
    });

    const module = device.createShaderModule({
        code: `
            struct Uniforms {
              matrix: mat4x4<f32>,
              color: vec4<f32>,
            };
            @group(0) @binding(0) var<uniform> uniforms: Uniforms;

            @vertex fn vs(
              @builtin(vertex_index) VertexIndex : u32
            ) -> @builtin(position) vec4<f32> {
              var pos = array<vec2<f32>, 3>(
                vec2(0.0, 0.5),
                vec2(-0.5, -0.5),
                vec2(0.5, -0.5)
              );

              return uniforms.matrix * vec4(pos[VertexIndex], 0.0, 1.0);
            }

            @fragment fn fs() -> @location(0) vec4<f32> {
              return uniforms.color;
            }
        `,
    });

    const uniformBuffer = device.createBuffer({
      size: (16 + 4) * 4,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });
    const uniformValues = new Float32Array(16 + 4);
    const matrix = uniformValues.subarray(0, 16);
    const color = uniformValues.subarray(16, 20);

    const pipeline = device.createRenderPipeline({
        layout: 'auto',
        vertex: {
            module,
            entryPoint: 'vs',
        },
        fragment: {
            module,
            entryPoint: 'fs',
            targets: [{format: presentationFormat}],
        },
    });

    const bindGroup = device.createBindGroup({
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: { buffer: uniformBuffer } },
      ],
    });

    const hsl = (h, s, l) => `hsl(${h * 360 | 0}, ${s * 100}%, ${l * 100 | 0}%)`;
    const cssColorToRGBA8 = (() => {
      const canvas = document.createElement('canvas');

      canvas.width = 1; 
      canvas.height = 1;
      const ctx = canvas.getContext('2d', {willReadFrequently: true});
      return cssColor => {
        ctx.clearRect(0, 0, 1, 1);
        ctx.fillStyle = cssColor;
        ctx.fillRect(0, 0, 1, 1);
        return Array.from(ctx.getImageData(0, 0, 1, 1).data);
      };
    })();
    const cssColorToRGBA = cssColor => cssColorToRGBA8(cssColor).map(v => v / 255);
    const hslToRGBA = (h, s, l) => cssColorToRGBA(hsl(h, s, l));

    function frame(time) {
        time *= 0.001;

        {
            const angle = time;
            const c = Math.cos(angle);
            const s = Math.sin(angle)
            matrix.set([
               c, s, 0, 0,
              -s, c, 0, 0,
               0, 0, 1, 0,
               0, 0, 0, 1,
            ]);
        }

        const hue = time * 0.1;
        color.set(hslToRGBA(hue, 1, 0.5));

        device.queue.writeBuffer(uniformBuffer, 0, uniformValues);

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginRenderPass({
            colorAttachments: [{
                view: context.getCurrentTexture().createView(),
                clearValue: hslToRGBA(hue + 0.5, 1, 0.5),
                loadOp: 'clear',
                storeOp: 'store',
            }],
        });
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);
        pass.draw(3);
        pass.end();

        device.queue.submit([encoder.finish()]);

        requestAnimationFrame(frame);
    }

    spector2.traceFrame().then(async (trace) => {
        // Trace the frame and set up the replay.
        console.log(trace);
        spector2.revertEntryPoints();
        const replay = await loadReplay(trace);
        console.log(replay);

        // Go through each command, and show the presented texture of the trace on the capture canvas.
        const captureCanvas = document.getElementById('captureCanvas');
        const context = captureCanvas.getContext('webgpu');

        for (const c of replay.commands) {
            replay.execute(c);

            if (c.name === 'present') {
                const textureState = c.args.texture;
                const device = textureState.device.webgpuObject;

                captureCanvas.width = textureState.size.width;
                captureCanvas.height = textureState.size.height;
                context.configure({
                    device,
                    usage: GPUTextureUsage.COPY_DST,
                    format: textureState.format,
                    alphaMode: 'opaque',
                });

                const encoder = device.createCommandEncoder();
                encoder.copyTextureToTexture(
                    {texture: textureState.webgpuObject},
                    {texture: context.getCurrentTexture()},
                    textureState.size
                );
                device.queue.submit([encoder.finish()]);
            }
        }
    });

    requestAnimationFrame(frame);
}
run();
</script>
</body>
</html>
